{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open(\"TwitterRawData.dat\", \"rb\") as filePath:\n",
    "    TwitterData = pd.DataFrame(pickle.load(file=filePath))[[\"id\", \"full_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1220957331149557765</td>\n",
       "      <td>i guess its time to switch majors. data scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220955374867701761</td>\n",
       "      <td>#TechnoCool: Data Science Community Rocked by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220954168057389056</td>\n",
       "      <td>Confused about how data science and data analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220953376189366272</td>\n",
       "      <td>Creating Robust Python Workflows: Learn to dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1220952323167440896</td>\n",
       "      <td>National Level Seminar on COMPUTATIONAL MATHEM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text\n",
       "0  1220957331149557765  i guess its time to switch majors. data scienc...\n",
       "1  1220955374867701761  #TechnoCool: Data Science Community Rocked by ...\n",
       "2  1220954168057389056  Confused about how data science and data analy...\n",
       "3  1220953376189366272  Creating Robust Python Workflows: Learn to dev...\n",
       "4  1220952323167440896  National Level Seminar on COMPUTATIONAL MATHEM..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1094 entries, 0 to 1093\n",
      "Data columns (total 2 columns):\n",
      "id           1094 non-null int64\n",
      "full_text    1094 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "TwitterData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1094.000000\n",
       "mean      178.421389\n",
       "std        78.420762\n",
       "min        23.000000\n",
       "25%       111.250000\n",
       "50%       168.000000\n",
       "75%       255.000000\n",
       "max       319.000000\n",
       "Name: full_text, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterData[\"full_text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "# Convert html encoded special characters to usable format\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(lambda x: html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Drop URI's completely.\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(\n",
    "    lambda x: re.sub(string = x, pattern = \"https\\:\\/\\/[\\w]+[.]?[\\w]+?[\\/\\w]+\\/*\", repl = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hash tags to split later into constituent words\n",
    "TwitterData[\"HashTags\"] = TwitterData[\"full_text\"].apply(lambda x: re.findall(string = x, pattern = r\"\\#\\w+\\b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts hashtags to plain words for later processing.\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(lambda x: re.sub(string = x, pattern = \"[\\#]*\", repl = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emails and @user\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(\n",
    "    lambda x: re.sub(string = x, pattern = \"\\b?[a-zA-Z0-9\\.\\_\\%\\+\\-]*@[a-zA-Z0-9\\.\\-\\_]+\\b?\", repl = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all text to lowercase to simply processing\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>HashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1220957331149557765</td>\n",
       "      <td>i guess its time to switch majors. data scienc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220955374867701761</td>\n",
       "      <td>technocool: data science community rocked by p...</td>\n",
       "      <td>[#TechnoCool, #tech, #technology, #datascience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220954168057389056</td>\n",
       "      <td>confused about how data science and data analy...</td>\n",
       "      <td>[#CareerKarma, #breakintotech, #21DayCkChallenge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220953376189366272</td>\n",
       "      <td>creating robust python workflows: learn to dev...</td>\n",
       "      <td>[#DataScience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1220952323167440896</td>\n",
       "      <td>national level seminar on computational mathem...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1220957331149557765  i guess its time to switch majors. data scienc...   \n",
       "1  1220955374867701761  technocool: data science community rocked by p...   \n",
       "2  1220954168057389056  confused about how data science and data analy...   \n",
       "3  1220953376189366272  creating robust python workflows: learn to dev...   \n",
       "4  1220952323167440896  national level seminar on computational mathem...   \n",
       "\n",
       "                                            HashTags  \n",
       "0                                                 []  \n",
       "1  [#TechnoCool, #tech, #technology, #datascience...  \n",
       "2  [#CareerKarma, #breakintotech, #21DayCkChallenge]  \n",
       "3                                     [#DataScience]  \n",
       "4                                                 []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(TwitterData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1094 entries, 0 to 1093\n",
      "Data columns (total 3 columns):\n",
      "id           1094 non-null int64\n",
      "full_text    1094 non-null object\n",
      "HashTags     1094 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 25.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(TwitterData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and normalize contractions and abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct mispellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing nltk modules\n",
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('tagsets')\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Reference Sentiment\n",
    ">Using TextBlob built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --trusted-host pypi.python.org textblob\n",
    "\n",
    "def GetTextBlobSentiments(TwitterData):\n",
    "    from textblob import TextBlob\n",
    "    import pandas as pd\n",
    "\n",
    "    sentimentData = pd.concat([\n",
    "        TwitterData[\"id\"],\n",
    "        pd.DataFrame(\n",
    "            columns = [\"TextBlobPolarity\", \"TextBlobSentiment\"],\n",
    "            data = [TextBlob(x).sentiment for x in TwitterData[\"full_text\"]],\n",
    "        )\n",
    "    ], axis = 1)\n",
    "    return sentimentData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwitterSentimentData = GetTextBlobSentiments(TwitterData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1094 entries, 0 to 1093\n",
      "Data columns (total 3 columns):\n",
      "id                   1094 non-null int64\n",
      "TextBlobPolarity     1094 non-null float64\n",
      "TextBlobSentiment    1094 non-null float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 25.8 KB\n"
     ]
    }
   ],
   "source": [
    "TwitterSentimentData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TextBlobPolarity</th>\n",
       "      <th>TextBlobSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1220957331149557765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220955374867701761</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220954168057389056</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220953376189366272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1220952323167440896</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1220950780783415298</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1220950425932726272</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1220949449528291329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1220949247249412096</td>\n",
       "      <td>0.268651</td>\n",
       "      <td>0.40377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1220948833565175808</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  TextBlobPolarity  TextBlobSentiment\n",
       "0  1220957331149557765          0.000000            0.00000\n",
       "1  1220955374867701761          0.500000            0.50000\n",
       "2  1220954168057389056          0.056250            0.55000\n",
       "3  1220953376189366272          0.000000            0.00000\n",
       "4  1220952323167440896         -0.600000            1.00000\n",
       "5  1220950780783415298          0.400000            0.90000\n",
       "6  1220950425932726272         -0.400000            0.70000\n",
       "7  1220949449528291329          0.000000            0.00000\n",
       "8  1220949247249412096          0.268651            0.40377\n",
       "9  1220948833565175808          0.500000            0.50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterSentimentData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Textblob polarity for classifier\n",
    "TwitterSentimentData[\"TextBlobPolarity(Bucketed)\"] = TwitterSentimentData[\"TextBlobPolarity\"].apply(lambda x: -1.0 if(x < -0.3) else 0.0 if (x < 0.3) else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TextBlobPolarity</th>\n",
       "      <th>TextBlobSentiment</th>\n",
       "      <th>TextBlobPolarity(Bucketed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.094000e+03</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.220764e+18</td>\n",
       "      <td>0.145139</td>\n",
       "      <td>0.311635</td>\n",
       "      <td>0.213894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.065543e+13</td>\n",
       "      <td>0.248656</td>\n",
       "      <td>0.291836</td>\n",
       "      <td>0.452652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.220597e+18</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.220699e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.220758e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.220825e+18</td>\n",
       "      <td>0.260691</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.220957e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  TextBlobPolarity  TextBlobSentiment  \\\n",
       "count  1.094000e+03       1094.000000        1094.000000   \n",
       "mean   1.220764e+18          0.145139           0.311635   \n",
       "std    9.065543e+13          0.248656           0.291836   \n",
       "min    1.220597e+18         -0.750000           0.000000   \n",
       "25%    1.220699e+18          0.000000           0.000000   \n",
       "50%    1.220758e+18          0.000000           0.300000   \n",
       "75%    1.220825e+18          0.260691           0.500000   \n",
       "max    1.220957e+18          1.000000           1.000000   \n",
       "\n",
       "       TextBlobPolarity(Bucketed)  \n",
       "count                 1094.000000  \n",
       "mean                     0.213894  \n",
       "std                      0.452652  \n",
       "min                     -1.000000  \n",
       "25%                      0.000000  \n",
       "50%                      0.000000  \n",
       "75%                      0.000000  \n",
       "max                      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterSentimentData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentiment data by training with pre-labeled text corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate word counts for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Sentiment Training Dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadYelpReviewData():\n",
    "    import pandas as pd\n",
    "    return pd.read_csv(\"YelpReviewData.csv\", dtype = {\"StarRating\": \"int8\", \"ReviewText\":\"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = LoadYelpReviewData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31157 entries, 0 to 31156\n",
      "Data columns (total 2 columns):\n",
      "StarRating    31157 non-null int8\n",
      "ReviewText    31157 non-null object\n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 274.0+ KB\n"
     ]
    }
   ],
   "source": [
    "TrainingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    7245\n",
       "4    7245\n",
       "1    7245\n",
       "3    5467\n",
       "2    3955\n",
       "Name: StarRating, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData[\"StarRating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand contractions and abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize words and tag parts of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop undesirable words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize adjectives, words, nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus.reader import wordnet\n",
    "from nltk.util import ngrams\n",
    "\n",
    "LemmatizerEngine = WordNetLemmatizer()\n",
    "\n",
    "POSTagToLemmaTag_Dict = {\n",
    "    \"J\" : wordnet.ADJ,\n",
    "    \"N\" : wordnet.NOUN,\n",
    "    \"V\" : wordnet.VERB,\n",
    "    \"R\" : wordnet.ADV,\n",
    "}\n",
    "\n",
    "def FilterForKeyWords(TextString):\n",
    "    removeWords_List = list(set([\n",
    "        # Prepositions\n",
    "        \"of\", \"with\", \"without\", \"at\", \"from\", \"into\", \"during\", \"including\", \"until\", \"against\", \"through\", \"throughput\",\n",
    "        \"towards\", \"to\", \"upon\", \"concerning\", \"in\", \"out\", \"for\", \"on\", \"below\", \"by\", \"over\", \"under\", \"despite\",\n",
    "        \"before\", \"after\", \"between\", \"since\", \"among\", \"along\", \"following\", \"across\", \"behind\", \"beyond\", \"except\",\n",
    "        \"but\", \"up\", \"down\", \"aboard\", \"amid\", \"as\", \"behind\", \"considering\", \"during\", \"inside\", \"minus\", \"off\", \"per\",\n",
    "        \"versus\", \"via\",\n",
    "    ]))\n",
    "    alphaCheck = re.compile(r\"^[a-z]+$\")\n",
    "\n",
    "    return str([LemmatizerEngine.lemmatize(word, POSTagToLemmaTag_Dict[pos[0]]) \n",
    "                for (word, pos) in nltk.pos_tag(nltk.word_tokenize(TextString.lower()))\n",
    "            if (\n",
    "                (len(word) > 1)\n",
    "                & (alphaCheck.match(word) != None)\n",
    "                & (word not in removeWords_List)\n",
    "                & (pos[0] in [\n",
    "                    \"J\",#\"JJ\", \"JJR\", \"JJS\", # Adjectives\n",
    "                    #\"N\",#\"NN\", \"NNS\", \"NNP\", \"NNPS\", # Nouns\n",
    "                    \"R\",#\"RB\", \"RBR\", \"RBS\", # Adverbs\n",
    "                    \"V\",#\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", #Verbs\n",
    "                    ])\n",
    "               )\n",
    "               ])\n",
    "\n",
    "def GetPrincipalWordCounts(DataFrame, TextColumnName, MinFreq = 2):\n",
    "    from datetime import datetime # For debugging performance data\n",
    "\n",
    "    Vectorizer = CountVectorizer(lowercase = False, strip_accents = \"ascii\", preprocessor = FilterForKeyWords,\n",
    "                                 min_df = MinFreq, ngram_range = (1, 3),\n",
    "                                )\n",
    "    startTime = datetime.now() # For debugging performance data\n",
    "    print(\"Starting Word Extraction at \" + str(startTime))\n",
    "\n",
    "    # Filter out unwanted words in each row, then create count columns for remaining words \n",
    "    WordCounts = pd.DataFrame(\n",
    "        Vectorizer.fit_transform(DataFrame[TextColumnName]).toarray(), \n",
    "        columns=Vectorizer.get_feature_names(), \n",
    "        dtype = \"uint\",\n",
    "    )\n",
    "\n",
    "    print(\"Execution Time: \" + str(datetime.now() - startTime)) # For debugging performance data\n",
    "\n",
    "    return WordCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Word Extraction at 2020-02-01 03:08:56.325881\n",
      "Execution Time: 0:03:07.965834\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31157 entries, 0 to 31156\n",
      "Columns: 1501 entries, able to yummy\n",
      "dtypes: uint32(1501)\n",
      "memory usage: 178.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainingDataWordCounts = GetPrincipalWordCounts(TrainingData, \"ReviewText\", MinFreq = 0.005)\n",
    "display(TrainingDataWordCounts.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>able get</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>act</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrap</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrong be</th>\n",
       "      <th>yell</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  able get  about  absolutely  accept  accommodate  acknowledge  act  \\\n",
       "0     0         0      0           0       0            0            0    0   \n",
       "1     0         0      0           0       0            0            0    0   \n",
       "2     0         0      0           0       0            0            0    0   \n",
       "3     0         0      0           0       0            0            1    0   \n",
       "4     0         0      0           0       0            0            0    0   \n",
       "\n",
       "   actual  actually  ...  worth  wrap  write  wrong  wrong be  yell  yes  yet  \\\n",
       "0       0         1  ...      0     0      0      0         0     0    0    0   \n",
       "1       0         0  ...      1     0      0      0         0     0    0    0   \n",
       "2       0         0  ...      0     0      0      0         0     0    0    0   \n",
       "3       0         0  ...      0     0      0      0         0     0    0    1   \n",
       "4       0         0  ...      0     0      0      0         0     0    0    0   \n",
       "\n",
       "   young  yummy  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDataWordCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "able          1157\n",
       "able get       177\n",
       "about          737\n",
       "absolutely    1138\n",
       "accept         212\n",
       "              ... \n",
       "yell           199\n",
       "yes            184\n",
       "yet            944\n",
       "young          480\n",
       "yummy          391\n",
       "Length: 1501, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDataWordCounts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match word count columns from Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Word Extraction at 2020-02-01 03:12:04.483752\n",
      "Execution Time: 0:00:01.697684\n"
     ]
    }
   ],
   "source": [
    "TwitterDataWordCounts = GetPrincipalWordCounts(TwitterData, \"full_text\", MinFreq = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TrainingDataWordCounts.columns) - set(TwitterDataWordCounts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TwitterDataWordCounts.columns) - set(TrainingDataWordCounts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns for words not in model\n",
    "\n",
    "def GetAlignedWordCounts(SourceData, ReferenceData):\n",
    "    # Setup resulting Dataframe to ensure word columns align.\n",
    "    wordCountsData = pd.DataFrame(columns = ReferenceData.columns)\n",
    "\n",
    "    # Copy over matching columns with data\n",
    "    for column in wordCountsData.columns.to_list():\n",
    "        if(column in SourceData.columns.to_list()):\n",
    "            wordCountsData[column] = SourceData[column]\n",
    "\n",
    "    # Fill missing word columns with 0\n",
    "    wordCountsData = wordCountsData.fillna(0)\n",
    "\n",
    "    for column in wordCountsData.columns.to_list():\n",
    "        wordCountsData[column] = wordCountsData[column].astype(\"int8\")\n",
    "\n",
    "    return wordCountsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1094 entries, 0 to 1093\n",
      "Columns: 1501 entries, able to yummy\n",
      "dtypes: int8(1501)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "SentimentDataWordCounts = GetAlignedWordCounts(TwitterDataWordCounts, TrainingDataWordCounts)\n",
    "SentimentDataWordCounts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    7245\n",
       "4    7245\n",
       "1    7245\n",
       "3    5467\n",
       "2    3955\n",
       "Name: StarRating, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData[\"StarRating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale to range of 2.0 to match range of -1.0 to 1.0 for textblob sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData[\"StarRating\"] = TrainingData[\"StarRating\"].map({1:2.0, 2:2.0, 3:3.0, 4:3.0, 5:4.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias by +3.0 to set zero point at 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentPredictionBias = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = pd.concat([TrainingData[\"StarRating\"], TrainingDataWordCounts], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31157 entries, 0 to 31156\n",
      "Columns: 1502 entries, StarRating to yummy\n",
      "dtypes: float64(1), uint32(1501)\n",
      "memory usage: 178.6 MB\n"
     ]
    }
   ],
   "source": [
    "TrainingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(TrainingData.drop(\"StarRating\", axis = 1), TrainingData[\"StarRating\"], test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24925, 1501)\n",
      "(24925,)\n",
      "(6232, 1501)\n",
      "(6232,)\n"
     ]
    }
   ],
   "source": [
    "print(Train_X.shape)\n",
    "print(Train_Y.shape)\n",
    "print(Test_X.shape)\n",
    "print(Test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through multiple classifiers and rank results\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "def AssessClassifierModels(TrainingDataColumns, TrainingDataResults, TestingDataColumns, TestingDataResults, Algorithms_List):\n",
    "    from datetime import datetime\n",
    "    functionStartTime = datetime.now()\n",
    "    print()\n",
    "    \n",
    "    # results container\n",
    "    results_list = pd.DataFrame()\n",
    "    \n",
    "    # calculated metrics and append to list\n",
    "    for algorithm in Algorithms_List:\n",
    "        loopStartTime = datetime.now()\n",
    "        print(\"Starting \" + str(algorithm.__name__) + \" at \" + str(loopStartTime))\n",
    "\n",
    "        algorithmObject = algorithm()\n",
    "        \n",
    "        if(str(algorithm.__name__) == \"XGBClassifier\"):\n",
    "            algorithmObject = XGBClassifier(nthread=4)\n",
    "\n",
    "        algorithmObject.fit(TrainingDataColumns, TrainingDataResults)\n",
    "        algorithmPredictions = algorithmObject.predict(TestingDataColumns)\n",
    "        (algorithmPrecision, algorithmRecall, algorithmF1, algorithmSupportList) = precision_recall_fscore_support(\n",
    "            TestingDataResults, algorithmPredictions, labels = np.sort(TrainingDataResults.unique()))\n",
    "        algorithmExecutionTime = str(datetime.now() - loopStartTime)\n",
    "        \n",
    "        results_list = results_list.append({\"Name\":  algorithm.__name__,\n",
    "                                            \"Precision\": algorithmPrecision,\n",
    "                                            \"Recall\": algorithmRecall,\n",
    "                                            \"F1\": algorithmF1,\n",
    "                                            \"Support\": algorithmSupportList,\n",
    "#                                            \"ConfusionMatrix\": \"\",# confusion_matrix(TestingDataResults, algorithmPredictions),\n",
    "                                            \"ModelData\" : algorithmObject,\n",
    "                                            \"ExecutionTime\": algorithmExecutionTime, \n",
    "                                            }, ignore_index = True)\n",
    "\n",
    "\n",
    "    # Set index to a meaningful value\n",
    "    results_list.set_index(\"Name\")\n",
    "    print(\"Assessment Complete.\")\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBClassifier at 2020-02-01 03:12:13.394766\n",
      "Starting MultinomialNB at 2020-02-01 03:12:57.244691\n",
      "Starting GaussianNB at 2020-02-01 03:12:59.067585\n",
      "Starting BernoulliNB at 2020-02-01 03:13:00.487441\n",
      "Starting DecisionTreeClassifier at 2020-02-01 03:13:03.857336\n",
      "Starting ExtraTreeClassifier at 2020-02-01 03:13:13.850055\n",
      "Assessment Complete.\n",
      "                     Name  \\\n",
      "0           XGBClassifier   \n",
      "1           MultinomialNB   \n",
      "2              GaussianNB   \n",
      "3             BernoulliNB   \n",
      "4  DecisionTreeClassifier   \n",
      "5     ExtraTreeClassifier   \n",
      "\n",
      "                                                       Precision  \\\n",
      "0   [0.7276134943773428, 0.6402753872633391, 0.7311015118790497]   \n",
      "1   [0.7999067164179104, 0.6867469879518072, 0.6706270627062706]   \n",
      "2  [0.7943676939426142, 0.6766081871345029, 0.44696969696969696]   \n",
      "3   [0.7854100106496272, 0.6864450127877237, 0.4610254272613589]   \n",
      "4   [0.6415525114155252, 0.5418586789554531, 0.4603616133518776]   \n",
      "5  [0.6116111611161116, 0.5266533066132264, 0.45874587458745875]   \n",
      "\n",
      "                                                          Recall  \\\n",
      "0  [0.7869369369369369, 0.7296979207532366, 0.46274777853725224]   \n",
      "1   [0.7725225225225225, 0.6932130247155748, 0.6944634313055366]   \n",
      "2   [0.6734234234234234, 0.4539034915653197, 0.8065618591934381]   \n",
      "3    [0.6644144144144144, 0.526480972930561, 0.7559808612440191]   \n",
      "4   [0.6328828828828829, 0.5535504119262455, 0.4524948735475051]   \n",
      "5   [0.6121621621621621, 0.5154962730482542, 0.4750512645249487]   \n",
      "\n",
      "                                                             F1  \\\n",
      "0   [0.7561133953689677, 0.682068206820682, 0.5667643365424865]   \n",
      "1  [0.7859761686526123, 0.6899648574775479, 0.6823371390194761]   \n",
      "2  [0.7289127254997562, 0.5433200281756281, 0.5751888861808433]   \n",
      "3  [0.7198633479746217, 0.5959147424511545, 0.5727602278612118]   \n",
      "4   [0.63718820861678, 0.5476421502037648, 0.45639434677697344]   \n",
      "5    [0.6118865375956776, 0.52101506740682, 0.4667562122229684]   \n",
      "\n",
      "              Support   ExecutionTime  \n",
      "0  [2220, 2549, 1463]  0:00:43.846914  \n",
      "1  [2220, 2549, 1463]  0:00:01.819130  \n",
      "2  [2220, 2549, 1463]  0:00:01.417622  \n",
      "3  [2220, 2549, 1463]  0:00:03.366941  \n",
      "4  [2220, 2549, 1463]  0:00:09.990503  \n",
      "5  [2220, 2549, 1463]  0:00:00.689509  \n"
     ]
    }
   ],
   "source": [
    "ClassifierResults_List = AssessClassifierModels(Train_X, Train_Y.apply(str).astype(\"category\"), Test_X, Test_Y.apply(str).astype(\"category\"), [XGBClassifier, MultinomialNB, GaussianNB, BernoulliNB, DecisionTreeClassifier, ExtraTreeClassifier])\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", 40):\n",
    "    print(ClassifierResults_List[[\"Name\", \"Precision\", \"Recall\", \"F1\", \"Support\", \"ExecutionTime\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictionModel = ClassifierResults_List.loc[ClassifierResults_List[\"Name\"] == \"MultinomialNB\", \"ModelData\"].iloc[0]\n",
    "PredictionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwitterSentimentData[\"PredictedPolarity\"] = pd.Series(PredictionModel.predict(SentimentDataWordCounts)).astype(\"float64\") - SentimentPredictionBias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare predictions to standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareClassificationPredictions(TestData, ComparisonData):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "    (precision, recall, f1score, supportList) = precision_recall_fscore_support(TestData, ComparisonData, labels = np.sort(TestData.unique()))\n",
    "    metrics = pd.DataFrame(data = {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1score,\n",
    "        \"Support\": supportList,\n",
    "        })\n",
    "\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", 100):\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(confusion_matrix(TestData, ComparisonData))\n",
    "        print(\"\")\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  9  11   0]\n",
      " [288 475  57]\n",
      " [ 69 125  60]]\n",
      "\n",
      "   Precision    Recall        F1  Support\n",
      "0   0.024590  0.450000  0.046632       20\n",
      "1   0.777414  0.579268  0.663871      820\n",
      "2   0.512821  0.236220  0.323450      254\n"
     ]
    }
   ],
   "source": [
    "CompareClassificationPredictions(TwitterSentimentData[\"TextBlobPolarity(Bucketed)\"], TwitterSentimentData[\"PredictedPolarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TextBlobPolarity</th>\n",
       "      <th>TextBlobSentiment</th>\n",
       "      <th>TextBlobPolarity(Bucketed)</th>\n",
       "      <th>PredictedPolarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.094000e+03</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.220764e+18</td>\n",
       "      <td>0.145139</td>\n",
       "      <td>0.311635</td>\n",
       "      <td>0.213894</td>\n",
       "      <td>-0.227605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.065543e+13</td>\n",
       "      <td>0.248656</td>\n",
       "      <td>0.291836</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0.624541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.220597e+18</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.220699e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.220758e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.220825e+18</td>\n",
       "      <td>0.260691</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.220957e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  TextBlobPolarity  TextBlobSentiment  \\\n",
       "count  1.094000e+03       1094.000000        1094.000000   \n",
       "mean   1.220764e+18          0.145139           0.311635   \n",
       "std    9.065543e+13          0.248656           0.291836   \n",
       "min    1.220597e+18         -0.750000           0.000000   \n",
       "25%    1.220699e+18          0.000000           0.000000   \n",
       "50%    1.220758e+18          0.000000           0.300000   \n",
       "75%    1.220825e+18          0.260691           0.500000   \n",
       "max    1.220957e+18          1.000000           1.000000   \n",
       "\n",
       "       TextBlobPolarity(Bucketed)  PredictedPolarity  \n",
       "count                 1094.000000        1094.000000  \n",
       "mean                     0.213894          -0.227605  \n",
       "std                      0.452652           0.624541  \n",
       "min                     -1.000000          -1.000000  \n",
       "25%                      0.000000          -1.000000  \n",
       "50%                      0.000000           0.000000  \n",
       "75%                      0.000000           0.000000  \n",
       "max                      1.000000           1.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterSentimentData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
