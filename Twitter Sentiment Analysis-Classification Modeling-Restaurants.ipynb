{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open(\"TwitterRawData-Food.dat\", \"rb\") as filePath:\n",
    "    TwitterData = pd.DataFrame(pickle.load(file=filePath))[[\"id\", \"full_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1222897127476449283</td>\n",
       "      <td>From Discover on Google https://t.co/Z6X7dxfZYq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1222897126625038339</td>\n",
       "      <td>Just getting to work at tandooritasteofindia f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1222897126419521538</td>\n",
       "      <td>\"Golden Milk\" #food #eat #health #tastyfix htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1222897125962342401</td>\n",
       "      <td>Halfway to work this morning I looked over at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1222897125144399878</td>\n",
       "      <td>lol guy can’t have any liquids after 7:30am. H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text\n",
       "0  1222897127476449283    From Discover on Google https://t.co/Z6X7dxfZYq\n",
       "1  1222897126625038339  Just getting to work at tandooritasteofindia f...\n",
       "2  1222897126419521538  \"Golden Milk\" #food #eat #health #tastyfix htt...\n",
       "3  1222897125962342401  Halfway to work this morning I looked over at ...\n",
       "4  1222897125144399878  lol guy can’t have any liquids after 7:30am. H..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      "id           10000 non-null int64\n",
      "full_text    10000 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "TwitterData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean       152.813800\n",
       "std         85.041669\n",
       "min          3.000000\n",
       "25%         81.000000\n",
       "50%        135.000000\n",
       "75%        230.000000\n",
       "max        328.000000\n",
       "Name: full_text, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterData[\"full_text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "# Convert html encoded special characters to usable format\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(lambda x: html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Drop URI's completely.\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(\n",
    "    lambda x: re.sub(string = x, pattern = \"https\\:\\/\\/[\\w]+[.]?[\\w]+?[\\/\\w]+\\/*\", repl = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hash tags to split later into constituent words\n",
    "TwitterData[\"HashTags\"] = TwitterData[\"full_text\"].apply(lambda x: re.findall(string = x, pattern = r\"\\#\\w+\\b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts hashtags to plain words for later processing.\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(lambda x: re.sub(string = x, pattern = \"[\\#]*\", repl = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emails and @user\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].apply(\n",
    "    lambda x: re.sub(string = x, pattern = \"\\b?[a-zA-Z0-9\\.\\_\\%\\+\\-]*@[a-zA-Z0-9\\.\\-\\_]+\\b?\", repl = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all text to lowercase to simply processing\n",
    "TwitterData[\"full_text\"] = TwitterData[\"full_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>HashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1222897127476449283</td>\n",
       "      <td>from discover on google</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1222897126625038339</td>\n",
       "      <td>just getting to work at tandooritasteofindia f...</td>\n",
       "      <td>[#indianeats, #foodstagram, #movingforwardpr, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1222897126419521538</td>\n",
       "      <td>\"golden milk\" food eat health tastyfix</td>\n",
       "      <td>[#food, #eat, #health, #tastyfix]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1222897125962342401</td>\n",
       "      <td>halfway to work this morning i looked over at ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1222897125144399878</td>\n",
       "      <td>lol guy can’t have any liquids after 7:30am. h...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1222897127476449283                           from discover on google    \n",
       "1  1222897126625038339  just getting to work at tandooritasteofindia f...   \n",
       "2  1222897126419521538            \"golden milk\" food eat health tastyfix    \n",
       "3  1222897125962342401  halfway to work this morning i looked over at ...   \n",
       "4  1222897125144399878  lol guy can’t have any liquids after 7:30am. h...   \n",
       "\n",
       "                                            HashTags  \n",
       "0                                                 []  \n",
       "1  [#indianeats, #foodstagram, #movingforwardpr, ...  \n",
       "2                  [#food, #eat, #health, #tastyfix]  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(TwitterData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "id           10000 non-null int64\n",
      "full_text    10000 non-null object\n",
      "HashTags     10000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(TwitterData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and normalize contractions and abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct mispellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing nltk modules\n",
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('tagsets')\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Reference Sentiment\n",
    ">Using TextBlob built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --trusted-host pypi.python.org textblob\n",
    "\n",
    "def GetTextBlobSentiments(TwitterData):\n",
    "    from textblob import TextBlob\n",
    "    import pandas as pd\n",
    "\n",
    "    sentimentData = pd.concat([\n",
    "        TwitterData[\"id\"],\n",
    "        pd.DataFrame(\n",
    "            columns = [\"TextBlobPolarity\", \"TextBlobSentiment\"],\n",
    "            data = [TextBlob(x).sentiment for x in TwitterData[\"full_text\"]],\n",
    "        )\n",
    "    ], axis = 1)\n",
    "    return sentimentData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwitterSentimentData = GetTextBlobSentiments(TwitterData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "id                   10000 non-null int64\n",
      "TextBlobPolarity     10000 non-null float64\n",
      "TextBlobSentiment    10000 non-null float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 234.5 KB\n"
     ]
    }
   ],
   "source": [
    "TwitterSentimentData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TextBlobPolarity</th>\n",
       "      <th>TextBlobSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1222897127476449283</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1222897126625038339</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.82500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1222897126419521538</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1222897125962342401</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1222897125144399878</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1222897120488742914</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1222897118962040833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1222897115317202949</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1222897113555599361</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1222897111890448385</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  TextBlobPolarity  TextBlobSentiment\n",
       "0  1222897127476449283              0.00            0.00000\n",
       "1  1222897126625038339              0.70            0.82500\n",
       "2  1222897126419521538              0.30            0.50000\n",
       "3  1222897125962342401              0.00            0.45625\n",
       "4  1222897125144399878              0.80            0.70000\n",
       "5  1222897120488742914              0.00            0.00000\n",
       "6  1222897118962040833              0.00            0.50000\n",
       "7  1222897115317202949              0.00            0.00000\n",
       "8  1222897113555599361              0.00            0.00000\n",
       "9  1222897111890448385              0.25            0.31250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterSentimentData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Textblob polarity for classifier\n",
    "TwitterSentimentData[\"TextBlobPolarity(Bucketed)\"] = TwitterSentimentData[\"TextBlobPolarity\"].apply(lambda x: -1.0 if(x < -0.3) else 0.0 if (x < 0.3) else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TextBlobPolarity</th>\n",
       "      <th>TextBlobSentiment</th>\n",
       "      <th>TextBlobPolarity(Bucketed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.222877e+18</td>\n",
       "      <td>0.133548</td>\n",
       "      <td>0.362760</td>\n",
       "      <td>0.204700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.210518e+13</td>\n",
       "      <td>0.287965</td>\n",
       "      <td>0.312239</td>\n",
       "      <td>0.495199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.222855e+18</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.222867e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.222878e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.222887e+18</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.222897e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  TextBlobPolarity  TextBlobSentiment  \\\n",
       "count  1.000000e+04      10000.000000       10000.000000   \n",
       "mean   1.222877e+18          0.133548           0.362760   \n",
       "std    1.210518e+13          0.287965           0.312239   \n",
       "min    1.222855e+18         -1.000000           0.000000   \n",
       "25%    1.222867e+18          0.000000           0.000000   \n",
       "50%    1.222878e+18          0.000000           0.400000   \n",
       "75%    1.222887e+18          0.285714           0.600000   \n",
       "max    1.222897e+18          1.000000           1.000000   \n",
       "\n",
       "       TextBlobPolarity(Bucketed)  \n",
       "count                10000.000000  \n",
       "mean                     0.204700  \n",
       "std                      0.495199  \n",
       "min                     -1.000000  \n",
       "25%                      0.000000  \n",
       "50%                      0.000000  \n",
       "75%                      0.000000  \n",
       "max                      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterSentimentData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentiment data by training with pre-labeled text corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate word counts for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Sentiment Training Dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadYelpReviewData():\n",
    "    import pandas as pd\n",
    "    return pd.read_csv(\"YelpReviewData.csv\", dtype = {\"StarRating\": \"int8\", \"ReviewText\":\"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = LoadYelpReviewData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31157 entries, 0 to 31156\n",
      "Data columns (total 2 columns):\n",
      "StarRating    31157 non-null int8\n",
      "ReviewText    31157 non-null object\n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 274.0+ KB\n"
     ]
    }
   ],
   "source": [
    "TrainingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    7245\n",
       "4    7245\n",
       "1    7245\n",
       "3    5467\n",
       "2    3955\n",
       "Name: StarRating, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData[\"StarRating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand contractions and abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize words and tag parts of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop undesirable words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize adjectives, words, nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus.reader import wordnet\n",
    "from nltk.util import ngrams\n",
    "\n",
    "LemmatizerEngine = WordNetLemmatizer()\n",
    "\n",
    "POSTagToLemmaTag_Dict = {\n",
    "    \"J\" : wordnet.ADJ,\n",
    "    \"N\" : wordnet.NOUN,\n",
    "    \"V\" : wordnet.VERB,\n",
    "    \"R\" : wordnet.ADV,\n",
    "}\n",
    "\n",
    "def FilterForKeyWords(TextString):\n",
    "    removeWords_List = list(set([\n",
    "        # Prepositions\n",
    "        \"of\", \"with\", \"without\", \"at\", \"from\", \"into\", \"during\", \"including\", \"until\", \"against\", \"through\", \"throughput\",\n",
    "        \"towards\", \"to\", \"upon\", \"concerning\", \"in\", \"out\", \"for\", \"on\", \"below\", \"by\", \"over\", \"under\", \"despite\",\n",
    "        \"before\", \"after\", \"between\", \"since\", \"among\", \"along\", \"following\", \"across\", \"behind\", \"beyond\", \"except\",\n",
    "        \"but\", \"up\", \"down\", \"aboard\", \"amid\", \"as\", \"behind\", \"considering\", \"during\", \"inside\", \"minus\", \"off\", \"per\",\n",
    "        \"versus\", \"via\",\n",
    "    ]))\n",
    "    alphaCheck = re.compile(r\"^[a-z]+$\")\n",
    "\n",
    "    return str([LemmatizerEngine.lemmatize(word, POSTagToLemmaTag_Dict[pos[0]]) \n",
    "                for (word, pos) in nltk.pos_tag(nltk.word_tokenize(TextString.lower()))\n",
    "            if (\n",
    "                (len(word) > 1)\n",
    "                & (alphaCheck.match(word) != None)\n",
    "                & (word not in removeWords_List)\n",
    "                & (pos[0] in [\n",
    "                    \"J\",#\"JJ\", \"JJR\", \"JJS\", # Adjectives\n",
    "                    #\"N\",#\"NN\", \"NNS\", \"NNP\", \"NNPS\", # Nouns\n",
    "                    \"R\",#\"RB\", \"RBR\", \"RBS\", # Adverbs\n",
    "                    \"V\",#\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", #Verbs\n",
    "                    ])\n",
    "               )\n",
    "               ])\n",
    "\n",
    "def GetPrincipalWordCounts(DataFrame, TextColumnName, MinFreq = 2):\n",
    "    from datetime import datetime # For debugging performance data\n",
    "\n",
    "    Vectorizer = CountVectorizer(lowercase = False, strip_accents = \"ascii\", preprocessor = FilterForKeyWords,\n",
    "                                 min_df = MinFreq, ngram_range = (1, 3),\n",
    "                                )\n",
    "    startTime = datetime.now() # For debugging performance data\n",
    "    print(\"Starting Word Extraction at \" + str(startTime))\n",
    "\n",
    "    # Filter out unwanted words in each row, then create count columns for remaining words \n",
    "    WordCounts = pd.DataFrame(\n",
    "        Vectorizer.fit_transform(DataFrame[TextColumnName]).toarray(), \n",
    "        columns=Vectorizer.get_feature_names(), \n",
    "        dtype = \"uint\",\n",
    "    )\n",
    "\n",
    "    print(\"Execution Time: \" + str(datetime.now() - startTime)) # For debugging performance data\n",
    "\n",
    "    return WordCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Word Extraction at 2020-02-01 03:14:36.499795\n",
      "Execution Time: 0:03:03.600446\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31157 entries, 0 to 31156\n",
      "Columns: 1501 entries, able to yummy\n",
      "dtypes: uint32(1501)\n",
      "memory usage: 178.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainingDataWordCounts = GetPrincipalWordCounts(TrainingData, \"ReviewText\", MinFreq = 0.005)\n",
    "display(TrainingDataWordCounts.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>able get</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>act</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrap</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrong be</th>\n",
       "      <th>yell</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  able get  about  absolutely  accept  accommodate  acknowledge  act  \\\n",
       "0     0         0      0           0       0            0            0    0   \n",
       "1     0         0      0           0       0            0            0    0   \n",
       "2     0         0      0           0       0            0            0    0   \n",
       "3     0         0      0           0       0            0            1    0   \n",
       "4     0         0      0           0       0            0            0    0   \n",
       "\n",
       "   actual  actually  ...  worth  wrap  write  wrong  wrong be  yell  yes  yet  \\\n",
       "0       0         1  ...      0     0      0      0         0     0    0    0   \n",
       "1       0         0  ...      1     0      0      0         0     0    0    0   \n",
       "2       0         0  ...      0     0      0      0         0     0    0    0   \n",
       "3       0         0  ...      0     0      0      0         0     0    0    1   \n",
       "4       0         0  ...      0     0      0      0         0     0    0    0   \n",
       "\n",
       "   young  yummy  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDataWordCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "able          1157\n",
       "able get       177\n",
       "about          737\n",
       "absolutely    1138\n",
       "accept         212\n",
       "              ... \n",
       "yell           199\n",
       "yes            184\n",
       "yet            944\n",
       "young          480\n",
       "yummy          391\n",
       "Length: 1501, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDataWordCounts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match word count columns from Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Word Extraction at 2020-02-01 03:17:40.292855\n",
      "Execution Time: 0:00:15.024799\n"
     ]
    }
   ],
   "source": [
    "TwitterDataWordCounts = GetPrincipalWordCounts(TwitterData, \"full_text\", MinFreq = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TrainingDataWordCounts.columns) - set(TwitterDataWordCounts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2306"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TwitterDataWordCounts.columns) - set(TrainingDataWordCounts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns for words not in model\n",
    "\n",
    "def GetAlignedWordCounts(SourceData, ReferenceData):\n",
    "    # Setup resulting Dataframe to ensure word columns align.\n",
    "    wordCountsData = pd.DataFrame(columns = ReferenceData.columns)\n",
    "\n",
    "    # Copy over matching columns with data\n",
    "    for column in wordCountsData.columns.to_list():\n",
    "        if(column in SourceData.columns.to_list()):\n",
    "            wordCountsData[column] = SourceData[column]\n",
    "\n",
    "    # Fill missing word columns with 0\n",
    "    wordCountsData = wordCountsData.fillna(0)\n",
    "\n",
    "    for column in wordCountsData.columns.to_list():\n",
    "        wordCountsData[column] = wordCountsData[column].astype(\"int8\")\n",
    "\n",
    "    return wordCountsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 1501 entries, able to yummy\n",
      "dtypes: int8(1501)\n",
      "memory usage: 14.3 MB\n"
     ]
    }
   ],
   "source": [
    "SentimentDataWordCounts = GetAlignedWordCounts(TwitterDataWordCounts, TrainingDataWordCounts)\n",
    "SentimentDataWordCounts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    7245\n",
       "4    7245\n",
       "1    7245\n",
       "3    5467\n",
       "2    3955\n",
       "Name: StarRating, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData[\"StarRating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale to range of 2.0 to match range of -1.0 to 1.0 for textblob sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData[\"StarRating\"] = TrainingData[\"StarRating\"].map({1:2.0, 2:2.0, 3:3.0, 4:3.0, 5:4.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias by +3.0 to set zero point at 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentPredictionBias = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = pd.concat([TrainingData[\"StarRating\"], TrainingDataWordCounts], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31157 entries, 0 to 31156\n",
      "Columns: 1502 entries, StarRating to yummy\n",
      "dtypes: float64(1), uint32(1501)\n",
      "memory usage: 178.6 MB\n"
     ]
    }
   ],
   "source": [
    "TrainingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(TrainingData.drop(\"StarRating\", axis = 1), TrainingData[\"StarRating\"], test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24925, 1501)\n",
      "(24925,)\n",
      "(6232, 1501)\n",
      "(6232,)\n"
     ]
    }
   ],
   "source": [
    "print(Train_X.shape)\n",
    "print(Train_Y.shape)\n",
    "print(Test_X.shape)\n",
    "print(Test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through multiple classifiers and rank results\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "def AssessClassifierModels(TrainingDataColumns, TrainingDataResults, TestingDataColumns, TestingDataResults, Algorithms_List):\n",
    "    from datetime import datetime\n",
    "    functionStartTime = datetime.now()\n",
    "    print()\n",
    "    \n",
    "    # results container\n",
    "    results_list = pd.DataFrame()\n",
    "    \n",
    "    # calculated metrics and append to list\n",
    "    for algorithm in Algorithms_List:\n",
    "        loopStartTime = datetime.now()\n",
    "        print(\"Starting \" + str(algorithm.__name__) + \" at \" + str(loopStartTime))\n",
    "\n",
    "        algorithmObject = algorithm()\n",
    "        \n",
    "        if(str(algorithm.__name__) == \"XGBClassifier\"):\n",
    "            algorithmObject = XGBClassifier(nthread=4)\n",
    "\n",
    "        algorithmObject.fit(TrainingDataColumns, TrainingDataResults)\n",
    "        algorithmPredictions = algorithmObject.predict(TestingDataColumns)\n",
    "        (algorithmPrecision, algorithmRecall, algorithmF1, algorithmSupportList) = precision_recall_fscore_support(\n",
    "            TestingDataResults, algorithmPredictions, labels = np.sort(TrainingDataResults.unique()))\n",
    "        algorithmExecutionTime = str(datetime.now() - loopStartTime)\n",
    "        \n",
    "        results_list = results_list.append({\"Name\":  algorithm.__name__,\n",
    "                                            \"Precision\": algorithmPrecision,\n",
    "                                            \"Recall\": algorithmRecall,\n",
    "                                            \"F1\": algorithmF1,\n",
    "                                            \"Support\": algorithmSupportList,\n",
    "#                                            \"ConfusionMatrix\": \"\",# confusion_matrix(TestingDataResults, algorithmPredictions),\n",
    "                                            \"ModelData\" : algorithmObject,\n",
    "                                            \"ExecutionTime\": algorithmExecutionTime, \n",
    "                                            }, ignore_index = True)\n",
    "\n",
    "\n",
    "    # Set index to a meaningful value\n",
    "    results_list.set_index(\"Name\")\n",
    "    print(\"Assessment Complete.\")\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBClassifier at 2020-02-01 03:19:11.562063\n",
      "Starting MultinomialNB at 2020-02-01 03:19:53.930942\n",
      "Starting GaussianNB at 2020-02-01 03:19:55.763812\n",
      "Starting BernoulliNB at 2020-02-01 03:19:57.167490\n",
      "Starting DecisionTreeClassifier at 2020-02-01 03:20:00.540235\n",
      "Starting ExtraTreeClassifier at 2020-02-01 03:20:10.457749\n",
      "Assessment Complete.\n",
      "                     Name                                Precision  \\\n",
      "0           XGBClassifier  [0.7276134943773428, 0.6402753872633...   \n",
      "1           MultinomialNB  [0.7999067164179104, 0.6867469879518...   \n",
      "2              GaussianNB  [0.7943676939426142, 0.6766081871345...   \n",
      "3             BernoulliNB  [0.7854100106496272, 0.6864450127877...   \n",
      "4  DecisionTreeClassifier  [0.6391659111514053, 0.5460475825019...   \n",
      "5     ExtraTreeClassifier  [0.6189624329159212, 0.5316259216142...   \n",
      "\n",
      "                                    Recall  \\\n",
      "0  [0.7869369369369369, 0.7296979207532...   \n",
      "1  [0.7725225225225225, 0.6932130247155...   \n",
      "2  [0.6734234234234234, 0.4539034915653...   \n",
      "3  [0.6644144144144144, 0.5264809729305...   \n",
      "4  [0.6351351351351351, 0.5582581404472...   \n",
      "5  [0.6234234234234234, 0.5374656728128...   \n",
      "\n",
      "                                        F1             Support   ExecutionTime  \n",
      "0  [0.7561133953689677, 0.6820682068206...  [2220, 2549, 1463]  0:00:42.366613  \n",
      "1  [0.7859761686526123, 0.6899648574775...  [2220, 2549, 1463]  0:00:01.829849  \n",
      "2  [0.7289127254997562, 0.5433200281756...  [2220, 2549, 1463]  0:00:01.401343  \n",
      "3  [0.7198633479746217, 0.5959147424511...  [2220, 2549, 1463]  0:00:03.370414  \n",
      "4  [0.6371441482150927, 0.5520853540252...  [2220, 2549, 1463]  0:00:09.915237  \n",
      "5  [0.6211849192100538, 0.5345298478345...  [2220, 2549, 1463]  0:00:00.703630  \n"
     ]
    }
   ],
   "source": [
    "ClassifierResults_List = AssessClassifierModels(Train_X, Train_Y.apply(str).astype(\"category\"), Test_X, Test_Y.apply(str).astype(\"category\"), [XGBClassifier, MultinomialNB, GaussianNB, BernoulliNB, DecisionTreeClassifier, ExtraTreeClassifier])\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", 40):\n",
    "    print(ClassifierResults_List[[\"Name\", \"Precision\", \"Recall\", \"F1\", \"Support\", \"ExecutionTime\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictionModel = ClassifierResults_List.loc[ClassifierResults_List[\"Name\"] == \"MultinomialNB\", \"ModelData\"].iloc[0]\n",
    "PredictionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwitterSentimentData[\"PredictedPolarity\"] = pd.Series(PredictionModel.predict(SentimentDataWordCounts)).astype(\"float64\") - SentimentPredictionBias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare predictions to standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareClassificationPredictions(TestData, ComparisonData):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "    (precision, recall, f1score, supportList) = precision_recall_fscore_support(TestData, ComparisonData, labels = np.sort(TestData.unique()))\n",
    "    metrics = pd.DataFrame(data = {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1score,\n",
    "        \"Support\": supportList,\n",
    "        })\n",
    "\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", 100):\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(confusion_matrix(TestData, ComparisonData))\n",
    "        print(\"\")\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 267  130   15]\n",
      " [2866 3690  573]\n",
      " [ 518 1075  866]]\n",
      "\n",
      "   Precision    Recall        F1  Support\n",
      "0   0.073131  0.648058  0.131430      412\n",
      "1   0.753830  0.517604  0.613772     7129\n",
      "2   0.595598  0.352176  0.442627     2459\n"
     ]
    }
   ],
   "source": [
    "CompareClassificationPredictions(TwitterSentimentData[\"TextBlobPolarity(Bucketed)\"], TwitterSentimentData[\"PredictedPolarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TextBlobPolarity</th>\n",
       "      <th>TextBlobSentiment</th>\n",
       "      <th>TextBlobPolarity(Bucketed)</th>\n",
       "      <th>PredictedPolarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.222877e+18</td>\n",
       "      <td>0.133548</td>\n",
       "      <td>0.362760</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>-0.21970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.210518e+13</td>\n",
       "      <td>0.287965</td>\n",
       "      <td>0.312239</td>\n",
       "      <td>0.495199</td>\n",
       "      <td>0.67991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.222855e+18</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.222867e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.222878e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.222887e+18</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.222897e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  TextBlobPolarity  TextBlobSentiment  \\\n",
       "count  1.000000e+04      10000.000000       10000.000000   \n",
       "mean   1.222877e+18          0.133548           0.362760   \n",
       "std    1.210518e+13          0.287965           0.312239   \n",
       "min    1.222855e+18         -1.000000           0.000000   \n",
       "25%    1.222867e+18          0.000000           0.000000   \n",
       "50%    1.222878e+18          0.000000           0.400000   \n",
       "75%    1.222887e+18          0.285714           0.600000   \n",
       "max    1.222897e+18          1.000000           1.000000   \n",
       "\n",
       "       TextBlobPolarity(Bucketed)  PredictedPolarity  \n",
       "count                10000.000000        10000.00000  \n",
       "mean                     0.204700           -0.21970  \n",
       "std                      0.495199            0.67991  \n",
       "min                     -1.000000           -1.00000  \n",
       "25%                      0.000000           -1.00000  \n",
       "50%                      0.000000            0.00000  \n",
       "75%                      0.000000            0.00000  \n",
       "max                      1.000000            1.00000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterSentimentData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
