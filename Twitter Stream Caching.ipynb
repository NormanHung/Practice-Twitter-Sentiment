{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from twython import Twython\n",
    "import pickle\n",
    "\n",
    "with open(\"TwitterKeys.dat\", \"rb\") as SaveFile:\n",
    "    ReadData = pickle.load(file=SaveFile)\n",
    "    \n",
    "TwitterStream = Twython(ReadData[\"ConsumerKey\"],ReadData[\"ConsumerSecret\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwitterData = TwitterStream.search(q=\"data science -filter:retweets AND -filter:replies\", max_id = 1220894112641114119, count=1000, tweet_mode = \"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(TwitterData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwitterData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwitterData[\"statuses\"][0][\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "print(TwitterData[\"search_metadata\"])\n",
    "print(TwitterData[\"search_metadata\"][\"next_results\"])\n",
    "\n",
    "urllib.parse.parse_qs((TwitterData[\"search_metadata\"][\"next_results\"]).replace(\"?\", \"\")).get(\"max_id\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "print(TwitterData[\"search_metadata\"])\n",
    "print(TwitterData[\"search_metadata\"][\"next_results\"])\n",
    "\n",
    "urllib.parse.parse_qs((TwitterData[\"search_metadata\"][\"next_results\"]).replace(\"?\", \"\")).get(\"max_id\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.iinfo(\"int64\").max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"TwitterRawData.dat\", \"wb\") as SaveFile:\n",
    "    pickle.dump(TwitterData, file=SaveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TwitterRawData.dat\", \"rb\") as SaveFile:\n",
    "    ReadData = pickle.load(file=SaveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ReadData[\"statuses\"][0][\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TwitterData[\"statuses\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One function loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetTweets(SearchTerms, MaxNumberOfTweets):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from twython import Twython\n",
    "    import pickle\n",
    "    import urllib\n",
    "    \n",
    "    # Get keys for Twitter Developer API\n",
    "    with open(\"TwitterKeys.dat\", \"rb\") as SaveFile:\n",
    "        ReadData = pickle.load(file=SaveFile)\n",
    "\n",
    "    twitterStream = Twython(ReadData[\"ConsumerKey\"],ReadData[\"ConsumerSecret\"])\n",
    "    \n",
    "    # Loop through stream until dry or max number of tweets reached\n",
    "    twitterData = []\n",
    "    max_id = int(np.iinfo(np.int64).max)\n",
    "\n",
    "    maxQueryCount = int(MaxNumberOfTweets / 100) * 2  # Limit of 100 tweets per request. Arbitrarily query twitter at least 2x as often\n",
    "    readTweetCount = 0\n",
    "    \n",
    "    for loopCount in range(maxQueryCount):\n",
    "        # Pull data from stream\n",
    "        streamData = twitterStream.search(\n",
    "            q=str([\"\\\"\" + term + \"\\\" \" for term in SearchTerms]) + \"-filter:retweets AND -filter:replies\", # Querystring, removing potential duplicates\n",
    "            max_id = max_id, # Get next set of tweets\n",
    "            tweet_mode = \"extended\", # 280 char support instead of legacy 140 char\n",
    "            count=MaxNumberOfTweets,\n",
    "        )\n",
    "        print(\"Loading \", str(len(streamData[\"statuses\"])), \" tweets.\")\n",
    "        # Save tweets\n",
    "        twitterData.append(streamData[\"statuses\"])\n",
    "        readTweetCount += len(streamData[\"statuses\"])\n",
    "\n",
    "        # Get max_id and update marker\n",
    "        max_id = streamData[\"search_metadata\"].get(\"next_results\")\n",
    "        if(max_id):\n",
    "            max_id = urllib.parse.parse_qs(max_id.replace(\"?\", \"\")).get(\"max_id\")\n",
    "            if(max_id):\n",
    "                max_id = int(max_id[0])\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # Check if got enough tweets\n",
    "        if(readTweetCount >= MaxNumberOfTweets):\n",
    "            break\n",
    "\n",
    "    # Return flattened list of tweets (statuses)\n",
    "    twitterData = pd.DataFrame([tweet for tweetGroup in twitterData for tweet in tweetGroup])\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Dupes: \", str(twitterData[\"id\"].duplicated().sum()))\n",
    "    print(\"\")\n",
    "    display(twitterData.info())\n",
    "    display(twitterData.head())\n",
    "    \n",
    "    return twitterData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  97  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  100  tweets.\n",
      "Loading  97  tweets.\n",
      "\n",
      "Dupes:  0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1094 entries, 0 to 1093\n",
      "Data columns (total 30 columns):\n",
      "created_at                   1094 non-null object\n",
      "id                           1094 non-null int64\n",
      "id_str                       1094 non-null object\n",
      "full_text                    1094 non-null object\n",
      "truncated                    1094 non-null bool\n",
      "display_text_range           1094 non-null object\n",
      "entities                     1094 non-null object\n",
      "metadata                     1094 non-null object\n",
      "source                       1094 non-null object\n",
      "in_reply_to_status_id        0 non-null object\n",
      "in_reply_to_status_id_str    0 non-null object\n",
      "in_reply_to_user_id          0 non-null object\n",
      "in_reply_to_user_id_str      0 non-null object\n",
      "in_reply_to_screen_name      0 non-null object\n",
      "user                         1094 non-null object\n",
      "geo                          6 non-null object\n",
      "coordinates                  6 non-null object\n",
      "place                        23 non-null object\n",
      "contributors                 0 non-null object\n",
      "is_quote_status              1094 non-null bool\n",
      "retweet_count                1094 non-null int64\n",
      "favorite_count               1094 non-null int64\n",
      "favorited                    1094 non-null bool\n",
      "retweeted                    1094 non-null bool\n",
      "lang                         1094 non-null object\n",
      "possibly_sensitive           966 non-null object\n",
      "extended_entities            321 non-null object\n",
      "quoted_status_id             55 non-null float64\n",
      "quoted_status_id_str         55 non-null object\n",
      "quoted_status                55 non-null object\n",
      "dtypes: bool(4), float64(1), int64(3), object(22)\n",
      "memory usage: 226.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Jan 25 06:31:26 +0000 2020</td>\n",
       "      <td>1220957331149557765</td>\n",
       "      <td>1220957331149557765</td>\n",
       "      <td>i guess its time to switch majors. data scienc...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 64]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Jan 25 06:23:40 +0000 2020</td>\n",
       "      <td>1220955374867701761</td>\n",
       "      <td>1220955374867701761</td>\n",
       "      <td>#TechnoCool: Data Science Community Rocked by ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 192]</td>\n",
       "      <td>{'hashtags': [{'text': 'TechnoCool', 'indices'...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://www.russelladvisors.org\" rel=\"...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat Jan 25 06:18:52 +0000 2020</td>\n",
       "      <td>1220954168057389056</td>\n",
       "      <td>1220954168057389056</td>\n",
       "      <td>Confused about how data science and data analy...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 198]</td>\n",
       "      <td>{'hashtags': [{'text': 'CareerKarma', 'indices...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat Jan 25 06:15:43 +0000 2020</td>\n",
       "      <td>1220953376189366272</td>\n",
       "      <td>1220953376189366272</td>\n",
       "      <td>Creating Robust Python Workflows: Learn to dev...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 164]</td>\n",
       "      <td>{'hashtags': [{'text': 'DataScience', 'indices...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://twitter.com/DD_NaNa_\" rel=\"no...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Jan 25 06:11:32 +0000 2020</td>\n",
       "      <td>1220952323167440896</td>\n",
       "      <td>1220952323167440896</td>\n",
       "      <td>National Level Seminar on COMPUTATIONAL MATHEM...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 130]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'fr', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>fr</td>\n",
       "      <td>False</td>\n",
       "      <td>{'media': [{'id': 1220952315739299840, 'id_str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Sat Jan 25 06:31:26 +0000 2020  1220957331149557765  1220957331149557765   \n",
       "1  Sat Jan 25 06:23:40 +0000 2020  1220955374867701761  1220955374867701761   \n",
       "2  Sat Jan 25 06:18:52 +0000 2020  1220954168057389056  1220954168057389056   \n",
       "3  Sat Jan 25 06:15:43 +0000 2020  1220953376189366272  1220953376189366272   \n",
       "4  Sat Jan 25 06:11:32 +0000 2020  1220952323167440896  1220952323167440896   \n",
       "\n",
       "                                           full_text  truncated  \\\n",
       "0  i guess its time to switch majors. data scienc...      False   \n",
       "1  #TechnoCool: Data Science Community Rocked by ...      False   \n",
       "2  Confused about how data science and data analy...      False   \n",
       "3  Creating Robust Python Workflows: Learn to dev...      False   \n",
       "4  National Level Seminar on COMPUTATIONAL MATHEM...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0            [0, 64]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1           [0, 192]  {'hashtags': [{'text': 'TechnoCool', 'indices'...   \n",
       "2           [0, 198]  {'hashtags': [{'text': 'CareerKarma', 'indices...   \n",
       "3           [0, 164]  {'hashtags': [{'text': 'DataScience', 'indices...   \n",
       "4           [0, 130]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "3  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "4  {'iso_language_code': 'fr', 'result_type': 're...   \n",
       "\n",
       "                                              source in_reply_to_status_id  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...                  None   \n",
       "1  <a href=\"http://www.russelladvisors.org\" rel=\"...                  None   \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                  None   \n",
       "3  <a href=\"https://twitter.com/DD_NaNa_\" rel=\"no...                  None   \n",
       "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                  None   \n",
       "\n",
       "   ... retweet_count favorite_count favorited retweeted lang  \\\n",
       "0  ...             1              0     False     False   en   \n",
       "1  ...             1              0     False     False   en   \n",
       "2  ...             1              0     False     False   en   \n",
       "3  ...             2              0     False     False   en   \n",
       "4  ...             2              0     False     False   fr   \n",
       "\n",
       "  possibly_sensitive                                  extended_entities  \\\n",
       "0                NaN                                                NaN   \n",
       "1              False                                                NaN   \n",
       "2              False                                                NaN   \n",
       "3              False                                                NaN   \n",
       "4              False  {'media': [{'id': 1220952315739299840, 'id_str...   \n",
       "\n",
       "  quoted_status_id quoted_status_id_str  quoted_status  \n",
       "0              NaN                  NaN            NaN  \n",
       "1              NaN                  NaN            NaN  \n",
       "2              NaN                  NaN            NaN  \n",
       "3              NaN                  NaN            NaN  \n",
       "4              NaN                  NaN            NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TwitterData = GetTweets([\"data science\"], 1000)\n",
    "\n",
    "# Save tweets to file\n",
    "import pickle\n",
    "with open(\"TwitterRawData.dat\", \"wb\") as SaveFile:\n",
    "    pickle.dump(TwitterData, file=SaveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
